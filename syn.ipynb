{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Text Embedding using BERT\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    def forward(self, text):\n",
    "        inputs = self.bert(text)[0]  # Using the last hidden state\n",
    "        return inputs.mean(dim=1)  # Averaging word embeddings\n",
    "\n",
    "# Generator Model (cGAN)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, text_emb_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_dim + text_emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, text_emb):\n",
    "        x = torch.cat([z, text_emb], dim=1)  # Concatenate noise and text embedding\n",
    "        return self.fc(x).view(-1, 3, 64, 64)  # Output image (64x64x3)\n",
    "\n",
    "# Discriminator Model (cGAN)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, text_emb_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(text_emb_dim + 3 * 64 * 64, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, text_emb):\n",
    "        x = torch.cat([img.view(img.size(0), -1), text_emb], dim=1)  # Concatenate image and text embedding\n",
    "        return self.fc(x)\n",
    "\n",
    "# Training Setup\n",
    "def train_gan(generator, discriminator, dataloader, text_encoder, device, epochs=10):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images, texts in dataloader:\n",
    "            # Convert text to embeddings\n",
    "            text_emb = text_encoder(texts).to(device)\n",
    "            \n",
    "            # Generate fake images\n",
    "            z = torch.randn(images.size(0), 100).to(device)  # Random noise\n",
    "            fake_images = generator(z, text_emb)\n",
    "\n",
    "            # Real images (label as 1) and fake images (label as 0)\n",
    "            real_labels = torch.ones(images.size(0), 1).to(device)\n",
    "            fake_labels = torch.zeros(images.size(0), 1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            real_out = discriminator(images.to(device), text_emb)\n",
    "            fake_out = discriminator(fake_images.detach(), text_emb)\n",
    "            d_loss_real = criterion(real_out, real_labels)\n",
    "            d_loss_fake = criterion(fake_out, fake_labels)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            g_out = discriminator(fake_images, text_emb)\n",
    "            g_loss = criterion(g_out, real_labels)  # Want generator to fool the discriminator\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
    "\n",
    "# Example of usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "text_encoder = TextEncoder().to(device)\n",
    "generator = Generator(z_dim=100, text_emb_dim=768).to(device)  # BERT's embedding size\n",
    "discriminator = Discriminator(text_emb_dim=768).to(device)\n",
    "\n",
    "# Example DataLoader and training (Replace with your dataset)\n",
    "dataloader = []  # Replace with your image-text dataset\n",
    "train_gan(generator, discriminator, dataloader, text_encoder, device)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
